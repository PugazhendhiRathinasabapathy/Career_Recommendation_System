{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file helps to Build and test the LLama model and Langchain functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building LLM\n",
    "llm = ChatGroq(\n",
    "    model='llama3-8b-8192',\n",
    "    groq_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    temperature=0.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hi Pugazh! I'm excited to help you explore your career options as an ML Engineer. Let's get started!\\n\\nHere's a question to help us get a better understanding of your goals and aspirations:\\n\\nWhat do you enjoy most about being an ML Engineer?\\n\\nA) The thrill of solving complex problems and creating innovative solutions\\nB) The opportunity to work with large datasets and analyze trends\\nC) The chance to collaborate with cross-functional teams and stakeholders\\nD) The ability to continuously learn and stay up-to-date with the latest advancements in the field\\n\\nWhich option best describes your experience and preferences?\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 123, 'prompt_tokens': 44, 'total_tokens': 167, 'completion_time': 0.1025, 'prompt_time': 0.008557389, 'queue_time': 0.11359555, 'total_time': 0.111057389}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None} id='run-8e9baca7-b44c-40b7-967c-78c76d08b2cd-0' usage_metadata={'input_tokens': 44, 'output_tokens': 123, 'total_tokens': 167}\n"
     ]
    }
   ],
   "source": [
    "#Getting response \n",
    "response = llm.invoke(\"you are a Career advisor ask the user some question with answer options using the following details: Name - Pugazh : Interests: Coding, profession : ML engineer\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
