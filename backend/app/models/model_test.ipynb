{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file helps to Build and test the LLama model and Langchain functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building LLM\n",
    "llm = ChatGroq(\n",
    "    model='llama3-8b-8192',\n",
    "    groq_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    temperature=0.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Here's a question to help determine your career path:\\n\\nWhen working on a project, what motivates you most?\\n\\nA) The opportunity to be creative and come up with innovative solutions\\nB) The chance to work with people and build strong relationships\\nC) The challenge of solving complex problems and overcoming obstacles\\nD) The sense of accomplishment and achieving specific goals\\n\\nWhich option resonates with you the most?\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 28, 'total_tokens': 111, 'completion_time': 0.069166667, 'prompt_time': 0.003874421, 'queue_time': 0.020889679, 'total_time': 0.073041088}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None} id='run-185f54cd-cdbc-4fc8-8996-b8c60b8ba80a-0' usage_metadata={'input_tokens': 28, 'output_tokens': 83, 'total_tokens': 111}\n"
     ]
    }
   ],
   "source": [
    "#Getting response \n",
    "response = llm.invoke(\"Ask me a question to determine my career path along with 4 options to chose from.\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleSearch Images Maps Play YouTube News Gmail Drive More »Web History | Settings | Sign in Advanced searchAdvertisingBusiness SolutionsAbout Google© 2025 - Privacy - Terms  "
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "url = \"https://www.google.com/\"\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "\n",
    "print(docs[0].page_content, end = ' ')  # Extracted text from the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import pandas as pd\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Load API keys\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Load O*NET data (assuming CSV format)\n",
    "df = pd.read_csv(\"onet_careers.csv\")  # Ensure this file has career details\n",
    "\n",
    "# Extract relevant fields\n",
    "career_docs = [\n",
    "    f\"Career: {row['Title']}. Description: {row['Description']}. Skills: {row['Skills']}. Education: {row['Education']}.\"\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "\n",
    "# Initialize ChromaDB\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "career_collection = chroma_client.get_or_create_collection(\"onet_careers\")\n",
    "\n",
    "# Store career documents as vectors\n",
    "vectorstore_careers = Chroma.from_texts(\n",
    "    career_docs, OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY), persist_directory=\"./chroma_db\"\n",
    ")\n",
    "vectorstore_careers.persist()\n",
    "\n",
    "print(\"✅ O*NET Career Data stored in ChromaDB!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_career(user_answers):\n",
    "    \"\"\"Retrieve the most relevant careers based on user responses.\"\"\"\n",
    "    user_profile = \" \".join(user_answers)  # Combine answers into a profile\n",
    "    results = vectorstore_careers.similarity_search(user_profile, k=3)  # Get top 3 matching careers\n",
    "    return [doc.page_content for doc in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_career_recommendation(user_answers):\n",
    "    \"\"\"Uses RAG to retrieve career matches & LLaMA to generate recommendations.\"\"\"\n",
    "    careers = get_best_career(user_answers)  # Fetch relevant careers\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Based on the user's responses:\n",
    "    {user_answers}\n",
    "    \n",
    "    Here are the most relevant careers:\n",
    "    {', '.join(careers)}\n",
    "\n",
    "    Provide a final career recommendation with an explanation.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
